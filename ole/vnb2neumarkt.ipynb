{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9143559d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of bus lines: [561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 573, 574, 575]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import partridge as ptg\n",
    "\n",
    "# Path to the GTFS zip file\n",
    "zip_path = \"../../GTFS.zip\"\n",
    "\n",
    "# Load stops.txt directly with partridge\n",
    "geo_feed= ptg.load_geo_feed(zip_path)\n",
    "bus_lines = [561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 573, 574, 575]\n",
    "print(\"List of bus lines:\", bus_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4497ef88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered routes for bus lines [561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 573, 574, 575]:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ole/anaconda3/envs/servus_ai/lib/python3.13/site-packages/pyproj/crs/crs.py:143: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n",
      "/home/ole/anaconda3/envs/servus_ai/lib/python3.13/site-packages/pyproj/crs/crs.py:143: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n"
     ]
    }
   ],
   "source": [
    "# Filter the GTFS dataset for the specified bus lines\n",
    "routes_df = geo_feed.routes\n",
    "nm_routes = routes_df[routes_df['route_short_name'].astype(str).isin([str(x) for x in bus_lines])]\n",
    "print(f\"Filtered routes for bus lines {bus_lines}:\")\n",
    "\n",
    "# Filter all GTFS schedule tables for the selected bus lines\n",
    "nm_route_ids = nm_routes['route_id']\n",
    "trips_df = geo_feed.trips\n",
    "nm_trips = trips_df[trips_df['route_id'].isin(nm_route_ids)]\n",
    "\n",
    "# stop times\n",
    "stop_times_df = geo_feed.stop_times\n",
    "nm_stop_times = stop_times_df[stop_times_df['trip_id'].isin(nm_trips['trip_id'])]\n",
    "\n",
    "# stops\n",
    "stops_df = geo_feed.stops\n",
    "nm_stops = stops_df[stops_df['stop_id'].isin(nm_stop_times['stop_id'])]\n",
    "\n",
    "# fix parent stations outside stadtwerke\n",
    "mask = ~nm_stops['parent_station'].isin(nm_stops['stop_id'])\n",
    "nm_stops.loc[mask, 'parent_station'] = \"\" \n",
    "\n",
    "# calendars\n",
    "calendar_df = geo_feed.calendar if hasattr(geo_feed, 'calendar') else None\n",
    "calendar_dates_df = geo_feed.calendar_dates if hasattr(geo_feed, 'calendar_dates') else None\n",
    "\n",
    "# transfers\n",
    "transfer_df = geo_feed.transfers\n",
    "\n",
    "# fix transfers only pick ones that do not go out of scope\n",
    "mask = transfer_df['to_stop_id'].isin(nm_stops[\"stop_id\"])\n",
    "transfer_df = transfer_df.loc[mask] \n",
    "mask = transfer_df['from_stop_id'].isin(nm_stops[\"stop_id\"])\n",
    "nm_transfers = transfer_df.loc[mask] \n",
    "\n",
    "#nm_agency =  #geo_feed.agency\n",
    "nm_agency = pd.DataFrame(\n",
    "    [['VGN', 'VGN', 'http://www.vgn.de', 'Europe/Berlin', 'DE', '+49 (0)911 27075-99']],\n",
    "    columns=[\n",
    "        'agency_id',\n",
    "        'agency_name',\n",
    "        'agency_url',\n",
    "        'agency_timezone',\n",
    "        'agency_lang',\n",
    "        'agency_phone'\n",
    "    ]\n",
    ")\n",
    "data = {\n",
    "    'feed_publisher_name': ['VGN'],\n",
    "    'feed_publisher_url': ['http://www.vgn.de'],\n",
    "    'feed_lang': ['de'],\n",
    "    'feed_version': ['1.0'],\n",
    "    'feed_start_date': ['20250810'],\n",
    "    'feed_end_date': ['20251108'],\n",
    "    \"feed_contact_email\": [\"email@email.com\"],\n",
    "    'feed_contact_url': [\"http://url.com\"]\n",
    "}\n",
    "\n",
    "# Create the pandas DataFrame\n",
    "nm_feed_info = pd.DataFrame(data)\n",
    "\n",
    "nm_routes.loc[:,\"agency_id\"]= \"VGN\"\n",
    "nm_routes.loc[nm_routes[\"route_id\"]==\"39-565-j25-2\", \"route_long_name\"] = \"Neumarkt Bahnhof - Zur√ºck\"\n",
    "\n",
    "gtfs_tables = {\n",
    "    \"trips.csv\": nm_trips,\n",
    "    \"stop_times.csv\": nm_stop_times,\n",
    "    \"stops.csv\": nm_stops,\n",
    "    \"routes.csv\": nm_routes,\n",
    "    \"transfers.csv\": nm_transfers,\n",
    "    \"agency.csv\": nm_agency,\n",
    "    \"feed_info.csv\": nm_feed_info\n",
    "}\n",
    "\n",
    "if calendar_df is not None:\n",
    "    gtfs_tables[\"calendar.csv\"] = calendar_df[calendar_df['service_id'].isin(nm_trips['service_id'])]\n",
    "if calendar_dates_df is not None:\n",
    "    gtfs_tables[\"calendar_dates.csv\"] = calendar_dates_df[calendar_dates_df['service_id'].isin(nm_trips['service_id'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b553f47d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1911    POINT (11.46522 49.27316)\n",
       "1912    POINT (11.46522 49.27324)\n",
       "1914    POINT (11.47749 49.29389)\n",
       "1916    POINT (11.47284 49.26636)\n",
       "1917    POINT (11.47309 49.26627)\n",
       "                  ...            \n",
       "2169    POINT (11.43514 49.27684)\n",
       "2170    POINT (11.43542 49.27681)\n",
       "2171    POINT (11.48979 49.28614)\n",
       "2172    POINT (11.52801 49.27605)\n",
       "2173    POINT (11.49016 49.28449)\n",
       "Name: geometry, Length: 212, dtype: geometry"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nm_stops[\"geometry\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cb0b453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trips.csv as neumarkt_parquet/trips.parquet\n",
      "Saved stop_times.csv as neumarkt_parquet/stop_times.parquet\n",
      "Saved stops.csv as neumarkt_parquet/stops.parquet\n",
      "Saved routes.csv as neumarkt_parquet/routes.parquet\n",
      "Saved transfers.csv as neumarkt_parquet/transfers.parquet\n",
      "Saved agency.csv as neumarkt_parquet/agency.parquet\n",
      "Saved feed_info.csv as neumarkt_parquet/feed_info.parquet\n",
      "Saved calendar.csv as neumarkt_parquet/calendar.parquet\n",
      "Saved calendar_dates.csv as neumarkt_parquet/calendar_dates.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ole/anaconda3/envs/servus_ai/lib/python3.13/site-packages/geopandas/geodataframe.py:1968: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "/home/ole/anaconda3/envs/servus_ai/lib/python3.13/site-packages/geopandas/geodataframe.py:1968: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Directory to save parquet files\n",
    "parquet_dir = \"neumarkt_parquet\"\n",
    "os.makedirs(parquet_dir, exist_ok=True)\n",
    "\n",
    "for name, table in gtfs_tables.items():\n",
    "    # If the table has a 'geometry' column, extract lat/lon and drop 'geometry'\n",
    "    if 'geometry' in table.columns:\n",
    "        # If using GeoPandas, geometry is a shapely Point\n",
    "        table['lat'] = table['geometry'].apply(lambda g: g.y if g is not None else None)\n",
    "        table['lon'] = table['geometry'].apply(lambda g: g.x if g is not None else None)\n",
    "        table = table.drop(columns=['geometry'])\n",
    "    parquet_path = os.path.join(parquet_dir, name.replace('.csv', '.parquet'))\n",
    "    table.to_parquet(parquet_path, index=False)\n",
    "    print(f\"Saved {name} as {parquet_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f77f095e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trips.csv as neumarkt_gtfs/trips.csv\n",
      "Saved stop_times.csv as neumarkt_gtfs/stop_times.csv\n",
      "Saved stops.csv as neumarkt_gtfs/stops.csv\n",
      "Saved routes.csv as neumarkt_gtfs/routes.csv\n",
      "Saved transfers.csv as neumarkt_gtfs/transfers.csv\n",
      "Saved agency.csv as neumarkt_gtfs/agency.csv\n",
      "Saved feed_info.csv as neumarkt_gtfs/feed_info.csv\n",
      "Saved calendar.csv as neumarkt_gtfs/calendar.csv\n",
      "Saved calendar_dates.csv as neumarkt_gtfs/calendar_dates.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import formatting\n",
    "import csv\n",
    "\n",
    "# Directory to save CSV files instead of a zip\n",
    "csv_dir = \"neumarkt_gtfs\"\n",
    "os.makedirs(csv_dir, exist_ok=True)\n",
    "\n",
    "for fname, df in gtfs_tables.items():\n",
    "    csv_path = os.path.join(csv_dir, fname)\n",
    "    df = formatting.format_df_for_gtfs(df)\n",
    "    # Sort columns for stops.txt\n",
    "    if fname == \"stops.txt\":\n",
    "        # Only keep columns that exist in the DataFrame, preserve order, append any extra columns at the end\n",
    "        ordered_cols = [col for col in stops_column_order if col in df.columns]\n",
    "        extra_cols = [col for col in df.columns if col not in ordered_cols]\n",
    "        df = df[ordered_cols + extra_cols]\n",
    "    df.to_csv(csv_path, index=False, quoting=csv.QUOTE_NONE, encoding='utf-8')\n",
    "    print(f\"Saved {fname} as {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b37399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3433022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e845415d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2807a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfad5d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add a new trip to a route using a reference trip and a time offset\n",
    "def add_trip_with_offset(reference_trip_id, time_offset_minutes, trips_df, stop_times_df):\n",
    "    \"\"\"\n",
    "    Adds a new trip based on a reference trip, shifting all stop_times by a given offset.\n",
    "    Args:\n",
    "        reference_trip_id (str): The trip_id to use as a template.\n",
    "        time_offset_minutes (int): Minutes to add to all times.\n",
    "        trips_df (pd.DataFrame): The trips table to update.\n",
    "        stop_times_df (pd.DataFrame): The stop_times table to update.\n",
    "    Returns:\n",
    "        (trips_df, stop_times_df): Updated DataFrames.\n",
    "    \"\"\"\n",
    "    import uuid\n",
    "    from datetime import datetime, timedelta\n",
    "    # Find the reference trip row\n",
    "    ref_trip = trips_df[trips_df['trip_id'] == reference_trip_id]\n",
    "    if ref_trip.empty:\n",
    "        raise ValueError(f\"Reference trip_id {reference_trip_id} not found.\")\n",
    "    # Generate a new unique trip_id\n",
    "    new_trip_id = str(uuid.uuid4())\n",
    "    # Copy the trip row and update trip_id\n",
    "    new_trip = ref_trip.iloc[0].to_dict()\n",
    "    new_trip['trip_id'] = new_trip_id\n",
    "    trips_df = pd.concat([trips_df, pd.DataFrame([new_trip])], ignore_index=True)\n",
    "    # Get stop_times for the reference trip\n",
    "    ref_stop_times = stop_times_df[stop_times_df['trip_id'] == reference_trip_id].copy()\n",
    "    def shift_time(t, offset):\n",
    "        if pd.isna(t): return t\n",
    "        try:\n",
    "            dt = datetime.strptime(t, \"%H:%M:%S\")\n",
    "            dt_shifted = dt + timedelta(minutes=offset)\n",
    "            # Handle times that go past midnight (GTFS allows 24:xx:xx etc)\n",
    "            hours = dt_shifted.hour + (dt_shifted.day - 1) * 24\n",
    "            return f\"{hours:02}:{dt_shifted.minute:02}:{dt_shifted.second:02}\"\n",
    "        except Exception:\n",
    "            return t\n",
    "    # Shift all times and assign new trip_id\n",
    "    new_stop_times = ref_stop_times.copy()\n",
    "    new_stop_times['trip_id'] = new_trip_id\n",
    "    for col in ['arrival_time', 'departure_time']:\n",
    "        if col in new_stop_times.columns:\n",
    "            new_stop_times[col] = new_stop_times[col].apply(lambda t: shift_time(t, time_offset_minutes))\n",
    "    stop_times_df = pd.concat([stop_times_df, new_stop_times], ignore_index=True)\n",
    "    return trips_df, stop_times_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261aeb92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b610b577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['stop_id', 'stop_name', 'location_type', 'parent_station', 'geometry'], dtype='object')\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99a02d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        POINT (10.14257 49.17557)\n",
       "1        POINT (10.14247 49.17563)\n",
       "2        POINT (10.12359 49.12538)\n",
       "3        POINT (10.12366 49.12534)\n",
       "4        POINT (10.12152 49.12358)\n",
       "                   ...            \n",
       "23336    POINT (10.69042 48.95366)\n",
       "23337     POINT (11.1686 50.35533)\n",
       "23338    POINT (11.01247 49.32776)\n",
       "23339    POINT (11.01229 49.32776)\n",
       "23340    POINT (11.01928 49.33709)\n",
       "Name: geometry, Length: 23341, dtype: geometry"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e8f2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load routes.txt to get the list of bus lines\n",
    "routes_df = ptg.load_geo_feed(zip_path).routes\n",
    "bus_lines = routes_df['route_short_name'].unique()\n",
    "bus_lines = sorted(bus_lines)\n",
    "print(\"List of bus lines:\")\n",
    "for line in bus_lines:\n",
    "    print(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "servus_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
