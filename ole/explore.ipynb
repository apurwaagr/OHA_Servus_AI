{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9143559d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of bus lines: [561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 573, 574, 575]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import partridge as ptg\n",
    "\n",
    "# Path to the GTFS zip file\n",
    "zip_path = \"../../vgn/GTFS.zip\"\n",
    "\n",
    "# Load stops.txt directly with partridge\n",
    "geo_feed= ptg.load_geo_feed(zip_path)\n",
    "bus_lines = [561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 573, 574, 575]\n",
    "print(\"List of bus lines:\", bus_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e42ce36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered routes for bus lines [561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 573, 574, 575]:\n"
     ]
    }
   ],
   "source": [
    "# Filter the GTFS dataset for the specified bus lines\n",
    "routes_df = geo_feed.routes\n",
    "filtered_routes = routes_df[routes_df['route_short_name'].astype(str).isin([str(x) for x in bus_lines])]\n",
    "print(f\"Filtered routes for bus lines {bus_lines}:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d629056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4497ef88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter all GTFS schedule tables for the selected bus lines\n",
    "nm_route_ids = filtered_routes['route_id']\n",
    "trips_df = geo_feed.trips\n",
    "nm_trips = trips_df[trips_df['route_id'].isin(nm_route_ids)]\n",
    "# stop times\n",
    "stop_times_df = geo_feed.stop_times\n",
    "nm_stop_times = stop_times_df[stop_times_df['trip_id'].isin(nm_trips['trip_id'])]\n",
    "# stops\n",
    "stops_df = geo_feed.stops\n",
    "nm_stops = stops_df[stops_df['stop_id'].isin(nm_stop_times['stop_id'])]\n",
    "\n",
    "# calendars\n",
    "calendar_df = geo_feed.calendar if hasattr(geo_feed, 'calendar') else None\n",
    "calendar_dates_df = geo_feed.calendar_dates if hasattr(geo_feed, 'calendar_dates') else None\n",
    "\n",
    "# transfers\n",
    "transfer_df = geo_feed.transfers\n",
    "nm_transfers = transfer_df[transfer_df[\"from_stop_id\"].isin(nm_stops[\"stop_id\"])]\n",
    "nm_agency =  geo_feed.agency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77f095e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GTFS feed written directly to neumarkt_gtfs.zip\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import io\n",
    "import formatting\n",
    "gtfs_zip_path = \"neumarkt_gtfs.zip\"\n",
    "\n",
    "# DataFrames to save: name -> DataFrame\n",
    "gtfs_tables = {\n",
    "    \"trips.txt\": nm_trips,\n",
    "    \"stop_times.txt\": nm_stop_times,\n",
    "    \"stops.txt\": nm_stops,\n",
    "    \"routes.txt\": filtered_routes,\n",
    "    \"transfers.txt\": nm_transfers,\n",
    "    \"agency.txt\": nm_agency,\n",
    "}\n",
    "if calendar_df is not None:\n",
    "    gtfs_tables[\"calendar.txt\"] = calendar_df[calendar_df['service_id'].isin(nm_trips['service_id'])]\n",
    "if calendar_dates_df is not None:\n",
    "    gtfs_tables[\"calendar_dates.txt\"] = calendar_dates_df[calendar_dates_df['service_id'].isin(nm_trips['service_id'])]\n",
    "\n",
    "with zipfile.ZipFile(gtfs_zip_path, mode=\"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
    "    for fname, df in gtfs_tables.items():\n",
    "        with io.StringIO() as buf:\n",
    "            df = formatting.format_df_for_gtfs(df)\n",
    "            df.to_csv(buf, index=False)\n",
    "            zf.writestr(fname, buf.getvalue())\n",
    "print(f\"GTFS feed written directly to {gtfs_zip_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a50f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "gtfs_zip_path = \"./neumarkt_gtfs.zip\"\n",
    "shutil.make_archive(\"./neumarkt_gtfs\", 'zip', nm_dir)\n",
    "print(f\"GTFS feed saved as {gtfs_zip_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfad5d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add a new trip to a route using a reference trip and a time offset\n",
    "def add_trip_with_offset(reference_trip_id, time_offset_minutes, trips_df, stop_times_df):\n",
    "    \"\"\"\n",
    "    Adds a new trip based on a reference trip, shifting all stop_times by a given offset.\n",
    "    Args:\n",
    "        reference_trip_id (str): The trip_id to use as a template.\n",
    "        time_offset_minutes (int): Minutes to add to all times.\n",
    "        trips_df (pd.DataFrame): The trips table to update.\n",
    "        stop_times_df (pd.DataFrame): The stop_times table to update.\n",
    "    Returns:\n",
    "        (trips_df, stop_times_df): Updated DataFrames.\n",
    "    \"\"\"\n",
    "    import uuid\n",
    "    from datetime import datetime, timedelta\n",
    "    # Find the reference trip row\n",
    "    ref_trip = trips_df[trips_df['trip_id'] == reference_trip_id]\n",
    "    if ref_trip.empty:\n",
    "        raise ValueError(f\"Reference trip_id {reference_trip_id} not found.\")\n",
    "    # Generate a new unique trip_id\n",
    "    new_trip_id = str(uuid.uuid4())\n",
    "    # Copy the trip row and update trip_id\n",
    "    new_trip = ref_trip.iloc[0].to_dict()\n",
    "    new_trip['trip_id'] = new_trip_id\n",
    "    trips_df = pd.concat([trips_df, pd.DataFrame([new_trip])], ignore_index=True)\n",
    "    # Get stop_times for the reference trip\n",
    "    ref_stop_times = stop_times_df[stop_times_df['trip_id'] == reference_trip_id].copy()\n",
    "    def shift_time(t, offset):\n",
    "        if pd.isna(t): return t\n",
    "        try:\n",
    "            dt = datetime.strptime(t, \"%H:%M:%S\")\n",
    "            dt_shifted = dt + timedelta(minutes=offset)\n",
    "            # Handle times that go past midnight (GTFS allows 24:xx:xx etc)\n",
    "            hours = dt_shifted.hour + (dt_shifted.day - 1) * 24\n",
    "            return f\"{hours:02}:{dt_shifted.minute:02}:{dt_shifted.second:02}\"\n",
    "        except Exception:\n",
    "            return t\n",
    "    # Shift all times and assign new trip_id\n",
    "    new_stop_times = ref_stop_times.copy()\n",
    "    new_stop_times['trip_id'] = new_trip_id\n",
    "    for col in ['arrival_time', 'departure_time']:\n",
    "        if col in new_stop_times.columns:\n",
    "            new_stop_times[col] = new_stop_times[col].apply(lambda t: shift_time(t, time_offset_minutes))\n",
    "    stop_times_df = pd.concat([stop_times_df, new_stop_times], ignore_index=True)\n",
    "    return trips_df, stop_times_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261aeb92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b610b577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['stop_id', 'stop_name', 'location_type', 'parent_station', 'geometry'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(stops_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99a02d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        POINT (10.14257 49.17557)\n",
       "1        POINT (10.14247 49.17563)\n",
       "2        POINT (10.12359 49.12538)\n",
       "3        POINT (10.12366 49.12534)\n",
       "4        POINT (10.12152 49.12358)\n",
       "                   ...            \n",
       "23336    POINT (10.69042 48.95366)\n",
       "23337     POINT (11.1686 50.35533)\n",
       "23338    POINT (11.01247 49.32776)\n",
       "23339    POINT (11.01229 49.32776)\n",
       "23340    POINT (11.01928 49.33709)\n",
       "Name: geometry, Length: 23341, dtype: geometry"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops_df[\"geometry\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e8f2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load routes.txt to get the list of bus lines\n",
    "routes_df = ptg.load_geo_feed(zip_path).routes\n",
    "bus_lines = routes_df['route_short_name'].unique()\n",
    "bus_lines = sorted(bus_lines)\n",
    "print(\"List of bus lines:\")\n",
    "for line in bus_lines:\n",
    "    print(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "servus_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
